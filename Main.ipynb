{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa59b95f",
   "metadata": {},
   "source": [
    "## TO DO:\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8e8e7b",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f0e6528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import EagarTsai as et\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from rl import CustomEnv\n",
    "import json\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21df0b0b",
   "metadata": {},
   "source": [
    "## Initialising fixed parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e5158a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Reading input file to get model parameter settings chosen by the user\"\"\"\n",
    "\n",
    "f = open(\"model_params_train.json\")\n",
    "data = json.load(f)\n",
    "\n",
    "# Assigning the values to variables so they can be used in the training and testing below\n",
    "\n",
    "timestep = data['timestep']                 # Number of timesteps in an episode\n",
    "max_steps = data['maximum_steps']           # Maximum number of timesteps across episodes in a single epoch\n",
    "epochs = data['epochs']                     # Total number of epochs\n",
    "model_alpha = data['model_alpha']           # Learning rate of the Bellmann equation\n",
    "model_gamma = data['model_gamma']           # Discount factor of the Bellmann equation\n",
    "model_epsilon = data['model_epsilon']       # Initial value for epsilon-greedy algorithm\n",
    "store_data = bool(data['store_data'])       # Boolean value whether to store data locally or not\n",
    "\n",
    "# The remaining varaibles dictate the minimum, maximum, and interval values for the three process parameters\n",
    "min_power = data['min_power']\n",
    "max_power = data['max_power']\n",
    "interval_power = data['interval_power']\n",
    "min_speed = data['min_speed']\n",
    "max_speed = data['max_speed']\n",
    "interval_speed = data['interval_speed']\n",
    "min_hatch = data['min_hatch']\n",
    "max_hatch = data['max_hatch']\n",
    "interval_hatch = data['interval_hatch']\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e796667a",
   "metadata": {},
   "source": [
    "## Creating parameter combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17f266b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "power = np.arange(min_power, max_power + 1, interval_power)\n",
    "speed = np.arange(min_speed, max_speed + 1, interval_speed)\n",
    "hatch = np.arange(min_hatch, max_hatch + 0.001, interval_hatch)\n",
    "\n",
    "parameters = []\n",
    "for p in power:\n",
    "    for s in speed:\n",
    "        for h in hatch:\n",
    "            parameters.append((p,s,h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e71ecb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1650"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f673a82",
   "metadata": {},
   "source": [
    "## Running training model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8479c48",
   "metadata": {},
   "source": [
    "#### The training model is where the model uses the epsilon greedy algorithm to explore the state space to find the state with the highest reward. The epsilon value comes into play and over time the agent begins exploiting more often, choosing the best action instead of a random one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc2a0721",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results = pd.DataFrame(columns = ['timesteps', 'test number', 'alpha', 'gamma', 'total steps', 'steps to optimal',\\\n",
    "                                     'optimal state', 'reward', 'reward per episode', 'time taken', 'no. of states visited'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af1c5051",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muadh\\Documents\\UoB\\Research Assistant\\Project\\EagarTsai.py:136: RuntimeWarning: invalid value encountered in sqrt\n",
      "  vx = (depth * width * (v ** 2)) / (4 * a * (1.5 * (depth + width / 2) - np.sqrt(depth * width / 2)))\n",
      "C:\\Users\\muadh\\Documents\\UoB\\Research Assistant\\Project\\EagarTsai.py:136: RuntimeWarning: invalid value encountered in sqrt\n",
      "  vx = (depth * width * (v ** 2)) / (4 * a * (1.5 * (depth + width / 2) - np.sqrt(depth * width / 2)))\n",
      "C:\\Users\\muadh\\Documents\\UoB\\Research Assistant\\Project\\EagarTsai.py:136: RuntimeWarning: invalid value encountered in sqrt\n",
      "  vx = (depth * width * (v ** 2)) / (4 * a * (1.5 * (depth + width / 2) - np.sqrt(depth * width / 2)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States visited in episode  1 of test 1 are  [359, 479, 368, 478, 489, 369, 368, 357, 236, 357, 366, 265, 266, 146, 36, 47, 46, 155, 154, 143, 42, 33, 44, 164, 53, 42, 52, 51, 52, 53, 52, 61, 172, 291, 290, 180, 300, 201, 202, 83, 182, 82, 71, 190, 70, 61, 160, 50, 40, 30, 150, 251, 151, 271, 381, 491, 381, 270, 380, 491, 391, 390, 490, 590, 471, 571, 680, 561, 672, 562, 561, 440, 441, 440, 441, 551, 550, 661, 552, 441, 551, 552, 441, 451, 341, 331, 450, 331, 220, 110, 221, 111, 1, 0, 110, 220, 121, 222, 332, 223, 122, 223, 332, 441, 330, 441, 551, 552, 452, 563, 444, 454, 455, 466, 565, 555, 664, 564, 573, 564, 565, 566, 666, 567, 457, 567, 676, 777, 887, 897, 1018, 1129, 1229, 1218, 1219, 1119, 1128, 1019, 1008, 907, 798, 688, 788, 677, 558, 458, 459, 349, 348, 228, 348, 349, 348, 358, 237, 138, 259, 368, 479, 359, 248, 239, 139, 239, 359, 478, 588, 699, 588, 589, 468, 589, 698, 597, 707, 588, 469, 369, 359, 358, 238, 137, 27, 28, 17, 126, 25, 35, 46, 55, 176, 295, 184, 285, 275, 175, 76, 187, 176, 287]\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muadh\\Documents\\UoB\\Research Assistant\\Project\\EagarTsai.py:136: RuntimeWarning: invalid value encountered in sqrt\n",
      "  vx = (depth * width * (v ** 2)) / (4 * a * (1.5 * (depth + width / 2) - np.sqrt(depth * width / 2)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States visited in episode  2 of test 1 are  [1062, 953, 834, 843, 723, 822, 721, 822, 922, 932, 1052, 931, 941, 931, 1042, 932, 831, 720, 821, 712, 701, 582, 573, 683, 792, 683, 573, 452, 451, 332, 233, 334, 444, 564, 665, 666, 667, 666, 665, 666, 665, 676, 775, 784, 903, 1024, 1033, 934, 1035, 1135, 1134, 1034, 915, 814, 823, 942, 1041, 1040, 920, 1020, 1031, 921, 1042, 1051, 1062, 1172, 1051, 951, 851, 960, 1080, 1090, 1091, 1090, 1081, 1180, 1291, 1410, 1310, 1300, 1421, 1420, 1531, 1422, 1423, 1313, 1314, 1424, 1313, 1422, 1411, 1302, 1191, 1190, 1310, 1411, 1302, 1301, 1422, 1423, 1422, 1411, 1400, 1390, 1291, 1410, 1420, 1310, 1200, 1091, 1192, 1191, 1080, 960, 1080, 1190, 1310, 1200, 1091, 971, 1082, 971, 852, 952, 953, 1064, 943, 934, 824, 945, 834, 723, 732, 731, 732, 633, 524, 513, 502, 393, 504, 505, 624, 524, 405, 304, 413, 302, 202, 81, 70, 60, 170, 171, 62, 61, 52, 173, 293, 173, 174, 65, 184, 295, 396, 387, 396, 496, 385, 274, 394, 283, 393, 394, 403, 302, 202, 91, 210, 100, 90, 80, 90, 80, 90, 200, 80, 90, 80, 81, 192, 201, 202, 311, 422, 301, 201, 191, 312, 423]\n",
      "------------------\n",
      "States visited in episode  3 of test 1 are  [1527, 1626, 1637, 1648, 1537, 1427, 1528, 1637, 1518, 1639, 1518, 1627, 1508, 1389, 1378, 1268, 1367, 1356, 1255, 1144, 1264, 1273, 1393, 1504, 1495, 1616, 1625, 1634, 1625, 1635, 1645, 1634, 1645, 1534, 1413, 1524, 1523, 1622, 1523, 1623, 1634, 1643, 1524, 1623, 1524, 1413, 1312, 1192, 1082, 971, 961, 1070, 1171, 1281, 1172, 1272, 1383, 1502, 1381, 1500, 1400, 1520, 1410, 1310, 1421, 1522, 1641, 1642, 1531, 1412, 1531, 1422, 1311, 1410, 1420, 1530, 1531, 1420, 1530, 1410, 1531, 1421, 1420, 1311, 1200, 1090, 1190, 1091, 981, 1091, 1090, 980, 971, 1081, 1182, 1171, 1160, 1280, 1180, 1291, 1182, 1171, 1172, 1061, 1171, 1060, 1180, 1060, 1180, 1071, 1180, 1291, 1290, 1280, 1400, 1390, 1290, 1300, 1200, 1190, 1310, 1201, 1312, 1301, 1421, 1420, 1421, 1312, 1191, 1181, 1290, 1280, 1390, 1510, 1411, 1311, 1302, 1191, 1071, 950, 850, 851, 862, 972, 983, 862, 751, 861, 871, 972, 1092, 1091, 1090, 1191, 1190, 1310, 1190, 1310, 1420, 1410, 1421, 1310, 1420, 1311, 1300, 1401, 1281, 1161, 1270, 1150, 1270, 1261, 1150, 1270, 1380, 1370, 1480, 1380, 1260, 1270, 1391, 1292, 1391, 1292, 1182, 1181, 1290, 1391, 1292, 1391, 1402, 1282, 1161, 1260, 1360, 1250, 1240, 1341, 1332, 1212]\n",
      "------------------\n",
      "States visited in episode  4 of test 1 are  [809, 689, 809, 819, 918, 807, 928, 829, 819, 718, 607, 598, 717, 597, 586, 486, 476, 377, 376, 387, 506, 606, 726, 727, 828, 829, 709, 599, 708, 699, 589, 698, 707, 827, 836, 945, 844, 744, 645, 766, 647, 757, 656, 647, 646, 765, 645, 544, 424, 415, 416, 307, 186, 296, 177, 187, 286, 175, 166, 155, 266, 257, 136, 16, 25, 26, 127, 227, 127, 8, 19, 29, 139, 128, 8, 129, 139, 19, 9, 118, 239, 238, 337, 227, 126, 245, 136, 17, 27, 18, 17, 28, 39, 159, 158, 257, 256, 247, 138, 237, 337, 228, 239, 339, 349, 249, 348, 228, 127, 118, 8, 118, 119, 18, 137, 18, 29, 18, 129, 28, 18, 8, 127, 128, 119, 19, 28, 38, 147, 47, 36, 47, 58, 49, 48, 148, 37, 27, 36, 46, 45, 146, 245, 346, 355, 255, 376, 387, 267, 166, 285, 186, 187, 177, 286, 165, 274, 265, 155, 164, 165, 155, 255, 155, 254, 133, 244, 145, 266, 377, 488, 498, 619, 519, 629, 739, 618, 507, 617, 506, 616, 516, 635, 754, 865, 974, 1083, 982, 863, 983, 1092, 1091, 1081, 1090, 970, 1080, 1180, 1291, 1290, 1180]\n",
      "------------------\n",
      "States visited in episode  5 of test 1 are  [522, 413, 414, 513, 523, 633, 742, 623, 614, 494, 593, 602, 712, 613, 714, 823, 812, 823, 933, 944, 1043, 1034, 1154, 1255, 1246, 1257, 1376, 1366, 1247, 1146, 1265, 1256, 1156, 1145, 1044, 1153, 1164, 1174, 1274, 1174, 1273, 1272, 1283, 1273, 1173, 1053, 1174, 1065, 1074, 1185, 1085, 1096, 1205, 1315, 1206, 1087, 1098, 1088, 969, 978, 1077, 967, 847, 836, 835, 844, 743, 732, 841, 851, 841, 851, 961, 1070, 1170, 1160, 1260, 1380, 1271, 1371, 1251, 1151, 1031, 1022, 923, 1032, 932, 1052, 1063, 1053, 1174, 1273, 1272, 1263, 1264, 1373, 1362, 1361, 1242, 1232, 1351, 1341, 1452, 1463, 1353, 1462, 1563, 1554, 1445, 1436, 1556, 1455, 1445, 1436, 1325, 1436, 1435, 1545, 1546, 1545, 1544, 1554, 1445, 1435, 1545, 1544, 1445, 1566, 1557, 1566, 1557, 1546, 1446, 1566, 1457, 1448, 1458, 1577, 1477, 1356, 1366, 1247, 1248, 1128, 1228, 1239, 1139, 1019, 1018, 1127, 1138, 1038, 1138, 1128, 1228, 1329, 1339, 1229, 1129, 1229, 1218, 1118, 1109, 998, 899, 889, 1009, 909, 799, 898, 997, 1117, 1007, 1016, 1005, 1114, 993, 893, 782, 771, 661, 550, 450, 340, 350, 230, 220, 340, 350, 361, 261, 360, 481, 381, 380, 280, 390, 401, 520, 401]\n",
      "------------------\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'Results'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [6], line 46\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m# If the user opts to store the results, then for each epoch the individual step results and the overall\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;66;03m# train results will be stored in separate excel files.\u001b[39;00m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m store_data:\n\u001b[1;32m---> 46\u001b[0m         \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mResults//Epoch \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m Step Results.xlsx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m         train_results\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreward\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto_excel(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResults//Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Train Results.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     49\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()           \u001b[38;5;66;03m# Ending timer for entire training\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2345\u001b[0m, in \u001b[0;36mNDFrame.to_excel\u001b[1;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, encoding, inf_rep, verbose, freeze_panes, storage_options)\u001b[0m\n\u001b[0;32m   2332\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexcel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExcelFormatter\n\u001b[0;32m   2334\u001b[0m formatter \u001b[38;5;241m=\u001b[39m ExcelFormatter(\n\u001b[0;32m   2335\u001b[0m     df,\n\u001b[0;32m   2336\u001b[0m     na_rep\u001b[38;5;241m=\u001b[39mna_rep,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2343\u001b[0m     inf_rep\u001b[38;5;241m=\u001b[39minf_rep,\n\u001b[0;32m   2344\u001b[0m )\n\u001b[1;32m-> 2345\u001b[0m \u001b[43mformatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexcel_writer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2347\u001b[0m \u001b[43m    \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartrow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartcol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartcol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreeze_panes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreeze_panes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2353\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\excel.py:888\u001b[0m, in \u001b[0;36mExcelFormatter.write\u001b[1;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options)\u001b[0m\n\u001b[0;32m    884\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    885\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    886\u001b[0m     \u001b[38;5;66;03m# error: Cannot instantiate abstract class 'ExcelWriter' with abstract\u001b[39;00m\n\u001b[0;32m    887\u001b[0m     \u001b[38;5;66;03m# attributes 'engine', 'save', 'supported_extensions' and 'write_cells'\u001b[39;00m\n\u001b[1;32m--> 888\u001b[0m     writer \u001b[38;5;241m=\u001b[39m \u001b[43mExcelWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[abstract]\u001b[39;49;00m\n\u001b[0;32m    889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    891\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_xlsxwriter.py:191\u001b[0m, in \u001b[0;36mXlsxWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAppend mode is not supported with xlsxwriter!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 191\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatetime_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatetime_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_sheet_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_sheet_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbook \u001b[38;5;241m=\u001b[39m Workbook(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mengine_kwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1106\u001b[0m, in \u001b[0;36mExcelWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m   1102\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m IOHandles(\n\u001b[0;32m   1103\u001b[0m     cast(IO[\u001b[38;5;28mbytes\u001b[39m], path), compression\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[0;32m   1104\u001b[0m )\n\u001b[0;32m   1105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, ExcelWriter):\n\u001b[1;32m-> 1106\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msheets: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   1110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcur_sheet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:694\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    692\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[0;32m    693\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[1;32m--> 694\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[0;32m    697\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    698\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:568\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    566\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[1;32m--> 568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'Results'"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()         # Beginning timer for the entire training\n",
    "\n",
    "for j in range(0, epochs):               # For each epoch\n",
    "    t1 = time.perf_counter()             # Beginning timer for the epoch\n",
    "      \n",
    "    # Creating instance of the environment\n",
    "    env = CustomEnv(parameters, timestep, model_alpha, model_gamma, model_epsilon)\n",
    "    \n",
    "    episode = 0                          # Initialising episode number to 0\n",
    "    states = set()                       # Total number of states visited in the epoch\n",
    "    states_visited = []                  # Total number of states visited in the episode\n",
    "    epoch_reward = 0                     # Total value of rewards in the epoch\n",
    "    episode_rewards = []                 # Set containing each episode's total reward\n",
    "\n",
    "    # As long as the maximum timesteps in an epoch is not exceeded\n",
    "    while(env.steps < max_steps):\n",
    "        env.reset(timestep)              # Resetting the environment\n",
    "        done = False                     # Setting done to be False so the episode restarts\n",
    "        episode += 1\n",
    "        total_reward = 0                 # Episode reward initialised to zero before start of episode\n",
    "        \n",
    "        while not done:                  # For each episode\n",
    "            reward, done = env.step(power, speed, hatch)\n",
    "            total_reward += reward\n",
    "            epoch_reward += reward\n",
    "            states_visited.append(env.state)\n",
    "            states.add(env.state)               \n",
    "                \n",
    "        print('States visited in episode ', episode, 'of test', j+1, 'are ', states_visited)\n",
    "        \n",
    "        episode_rewards.append(total_reward)\n",
    "        print('------------------')\n",
    "        states_visited.clear()\n",
    "    \n",
    "    t2 = time.perf_counter()             # Ending timer for the epoch\n",
    "    time_taken = t2 - t1                 # Calculating time taken for the epoch to run\n",
    "    \n",
    "    row = pd.Series([timestep, j + 1, env.alpha, env.gamma, env.steps, env.optimal_steps, env.optimal_state, \\\n",
    "                     env.rmax, epoch_reward / episode, time_taken, len(states)], \\\n",
    "                    index = train_results.columns)\n",
    "    train_results.loc[len(train_results)] = row\n",
    "    \n",
    "    # If the user opts to store the results, then for each epoch the individual step results and the overall\n",
    "    # train results will be stored in separate excel files.\n",
    "    if store_data:\n",
    "        env.results.to_excel(f'Train Results//Epoch {j + 1} Step Results.xlsx')\n",
    "        train_results.sort_values('reward', ascending = False).to_excel(f'Train Results//Epoch {j + 1} Train Results.xlsx')\n",
    "        \n",
    "end_time = time.perf_counter()           # Ending timer for entire training\n",
    "\n",
    "time_elapsed = end_time - start_time     # Calculating time taken for the whole training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0679709",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Elapsed Time is', time_elapsed / 60, 'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7332d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Exporting results to an Excel sheet\"\"\"\n",
    "\n",
    "#train_results = pd.read_excel('Tugrul Results.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bdaebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Importing results from an Excel sheet\"\"\"\n",
    "\n",
    "#train_results.to_excel('Pre-Paper Results.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71846446",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Displaying training details for each epoch\"\"\"\n",
    "\n",
    "train_results.sort_values('reward', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6968be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Printing best parameter configuration from each epoch\"\"\"\n",
    "\n",
    "print(\"Optimal parameter configurations (P, v, h):\\n\")\n",
    "for i in range(epochs):\n",
    "    opt_state = train_results['optimal state'][i]\n",
    "    print(f\"Epoch {i + 1}: {parameters[int(opt_state)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f333785",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Storing Q table as an Excel file if required for testing\"\"\"\n",
    "\n",
    "# df = pd.DataFrame(data=env.qtable)\n",
    "\n",
    "# df = (df.T)\n",
    "\n",
    "# df.to_excel('Qtable_train.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8acc1f",
   "metadata": {},
   "source": [
    "### Test Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa3864b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"If a specific Qtable is to be used, then import it here, otherwise the one from the train model is used\"\"\"\n",
    "try:\n",
    "    filename = \"Qtable_train.xlsx\"\n",
    "    qtable = pd.read_excel(filename)\n",
    "    print(\"Using imported Q-table\")\n",
    "except:\n",
    "    qtable = env.qtable\n",
    "    print(\"Using Q-table from train model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f143fa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Reading input file to get model parameter settings chosen by the user for testing\"\"\"\n",
    "\n",
    "f = open(\"model_params_test.json\")\n",
    "data = json.load(f)\n",
    "\n",
    "# Assigning the values to variables so they can be used in the training and testing below\n",
    "\n",
    "timestep = data['timestep']                 # Number of timesteps in an episode\n",
    "max_steps = data['maximum_steps']           # Maximum number of timesteps across episodes in a single epoch\n",
    "epochs = data['epochs']                     # Total number of epochs\n",
    "model_alpha = data['model_alpha']           # Learning rate of the Bellmann equation\n",
    "model_gamma = data['model_gamma']           # Discount factor of the Bellmann equation\n",
    "model_epsilon = data['model_epsilon']       # Initial value for epsilon-greedy algorithm\n",
    "store_data = bool(data['store_data'])       # Boolean value whether to store data locally or not\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e7a38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = pd.DataFrame(columns = ['timestep', 'test number', 'alpha', 'gamma', 'total steps', 'steps to optimal',\\\n",
    "                                     'optimal state', 'reward', 'reward per episode', 'time taken', \\\n",
    "                                        'number of states'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384a7d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a table to record only the reward for each episode\n",
    "test_reward_table = pd.DataFrame(index = np.arange(1, 6, 1))\n",
    "test_reward_table.index.name = 'Episode Number'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986502b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.perf_counter()         # Beginning timer for the entire training\n",
    "\n",
    "for j in range(0,epochs):                # For each epoch\n",
    "    t1 = time.perf_counter()             # Beginning timer for the epoch\n",
    "    \n",
    "    # Creating instance of the environment\n",
    "    env_test = CustomEnv(parameters, timestep, model_alpha, model_gamma, model_epsilon, qtable = qtable)\n",
    "    \n",
    "    episode = 0                          # Initialising episode number to 0\n",
    "    states = set()                       # Total number of states visited in the epoch\n",
    "    states_visited = []                  # Total number of states visited in the episode\n",
    "    epoch_reward = 0                     # Total value of rewards in the epoch\n",
    "    episode_rewards = []                 # Set containing each episode's total reward\n",
    "\n",
    "    # As long as the maximum timesteps in an epoch is not exceeded\n",
    "    while(env_test.steps < max_steps):\n",
    "        env_test.reset(timestep)         # Resetting the environment\n",
    "        done = False                     # Setting done to be False so the episode restarts\n",
    "        episode += 1                     \n",
    "        total_reward = 0                 # Episode reward initialisd to zero before start of episode\n",
    "        \n",
    "        while not done:                  # For each episode\n",
    "            reward, done = env_test.step(power, speed, hatch, test = True)\n",
    "            total_reward += reward\n",
    "            epoch_reward += reward\n",
    "            states_visited.append(env_test.state)\n",
    "            states.add(env_test.state)\n",
    "        print('States visited in episode ', episode, 'of test', j+1, 'are ', states_visited)\n",
    "        \n",
    "        episode_rewards.append(total_reward)  \n",
    "        print('------------------')\n",
    "        states_visited.clear()\n",
    "    \n",
    "    t2 = time.perf_counter()             # Ending timer for the epoch\n",
    "    time_taken = t2 - t1                 # Calculating time taken for the epoch to run\n",
    "    \n",
    "    test_reward_table[f'test {j + 1} rewards'] = episode_rewards\n",
    "    row = pd.Series([timestep, j + 1, env_test.alpha, env_test.gamma, env_test.steps, env_test.optimal_steps,\\\n",
    "                     env_test.optimal_state, env_test.rmax, epoch_reward / episode, time_taken, \\\n",
    "                     len(states)], index = test_results.columns)\n",
    "    test_results.loc[len(test_results)] = row\n",
    "    \n",
    "    # If the user opts to store the results, then for each epoch the individual step results and the overall\n",
    "    # train results will be stored in separate excel files.\n",
    "    if store_data:\n",
    "        env.results.to_excel(f'Test Results//Epoch {j + 1} Step Results.xlsx')\n",
    "        test_results.sort_values('reward', ascending = False).to_excel(f'Test Results//Epoch {j + 1} Test Results.xlsx')\n",
    "\n",
    "    \n",
    "end_time = time.perf_counter()           # Ending timer for entire training\n",
    "\n",
    "time_elapsed = end_time - start_time     # Calculating time taken for the whole training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765ce676",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Elapsed Time is', time_elapsed / 60, 'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04b8e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_reward_table.to_excel('Test Reward table 3.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4251a7bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_results.sort_values('reward', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b9387e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Printing best parameter configuration from each epoch\"\"\"\n",
    "\n",
    "print(\"Optimal parameter configurations (P, v, h):\\n\")\n",
    "for i in range(epochs):\n",
    "    opt_state = test_results['optimal state'][i]\n",
    "    print(f\"Epoch {i + 1}: {parameters[int(opt_state)]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
